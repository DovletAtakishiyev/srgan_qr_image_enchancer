{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNxr3GCVCtokndj0CwBU4/X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Установка зависимостей + распаковка данных"],"metadata":{"id":"HOKseobGe15I"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Syn7w5OdQHsR"},"outputs":[],"source":["#downloading the main model architecture\n","!wget https://raw.githubusercontent.com/PsVenom/QR-code-enhancement-using-SRGANs/main/main.py"]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"metadata":{"id":"AD0oiAH2QaUr","executionInfo":{"status":"ok","timestamp":1716766668205,"user_tz":-180,"elapsed":376,"user":{"displayName":"Ma To","userId":"08961984481679234525"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!pip install opencv-python\n","!pip install tqdm\n","!pip install scikit-image"],"metadata":{"id":"Kw04P3nwQd6D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Cмотрим на один пример"],"metadata":{"id":"Hq33Rzx7e8W6"}},{"cell_type":"code","source":["import cv2\n","import os\n","\n","ddatadir = '../input/qrimagesaugmented/content/qr_augmented'\n","\n","# перебор только одного элемента\n","for img in os.listdir(datadir):\n","    img_array = cv2.imread(os.path.join(datadir, img), cv2.IMREAD_GRAYSCALE)  # преобразование в массив\n","    plt.imshow(img_array, cmap='gray')  # отображение графика\n","    plt.show()  # отображение!\n","\n","    break  # нужен только один для примера, поэтому выходим"],"metadata":{"id":"jl995_EVQhtY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Сохранение изображения"],"metadata":{"id":"W29PHM0ufIaK"}},{"cell_type":"code","source":["array = []\n","array_small = []\n","\n","def create_training_data():\n","    for img in tqdm(list(os.listdir(datadir))):  # перебор каждого изображения\n","        try:\n","            img_array = cv2.imread(os.path.join(datadir, img), cv2.IMREAD_COLOR)  # преобразование в массив\n","            new_array = cv2.resize(img_array, (128, 128))  # изменение размера для нормализации данных\n","            array.append([new_array])  # добавление в обучающие данные\n","            array_small.append([cv2.resize(img_array, (32, 32),\n","                                           interpolation=cv2.INTER_AREA)])  # добавление в обучающие данные (уменьшенный размер)\n","        except Exception as e:  # для чистоты вывода пропускаем исключения\n","            pass\n","\n","create_training_data()"],"metadata":{"id":"P_XO8joiQnWy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(array)"],"metadata":{"id":"-PHr-ddLQnO6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Загрузка дополненных изображений и добвление в массив"],"metadata":{"id":"TOHa3_DYfTS4"}},{"cell_type":"code","source":["X =  []\n","Xs = []\n","for features in array:\n","    X.append(features)\n","for features in array_small:\n","    Xs.append(features)\n","plt.figure(figsize=(16, 8))\n","X = np.array(X).reshape(-1, 128, 128, 3)\n","Xs = np.array(Xs).reshape(-1, 32, 32, 3)\n","plt.subplot(231)\n","plt.imshow(X[0], cmap = 'gray')\n","plt.subplot(233)\n","plt.imshow(Xs[0], cmap = 'gray')\n","plt.show()"],"metadata":{"id":"mYXz43AEQr5G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Обучение и валидация"],"metadata":{"id":"OaE74cWlffiI"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train,X_valid,y_train, y_valid = train_test_split(Xs, X, test_size = 0.33, random_state = 12)\n","X_train.shape"],"metadata":{"id":"pHN_orQpQuHz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from main import *"],"metadata":{"id":"HWClgMO5Qvtn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Создание конечной генеративной модели"],"metadata":{"id":"hbbdCYQ4foTM"}},{"cell_type":"code","source":["# модели генератора и дискриминатора взяты из файла main.py\n","hr_shape = (y_train.shape[1], y_train.shape[2], y_train.shape[3])\n","lr_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n","\n","lr_ip = Input(shape=lr_shape)\n","hr_ip = Input(shape=hr_shape)\n","\n","generator = generator(lr_ip, res_range = 16, upscale_range=2)\n","generator.summary()\n","\n","discriminator = discriminator(hr_ip)\n","discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n","discriminator.summary()\n","\n","vgg = build_vgg((128,128,3))\n","print(vgg.summary())\n","vgg.trainable = False\n","\n","gan_model = create_comb(generator, discriminator, vgg, lr_ip, hr_ip)"],"metadata":{"id":"7BmjdO8OQx7C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# подготовка пакетов данных\n","batch_size = 1\n","train_lr_batches = []\n","train_hr_batches = []\n","for it in range(int(y_train.shape[0] / batch_size)):\n","    start_idx = it * batch_size\n","    end_idx = start_idx + batch_size\n","    train_hr_batches.append(y_train[start_idx:end_idx])\n","    train_lr_batches.append(X_train[start_idx:end_idx])"],"metadata":{"id":"tnpLJQtLQ1hQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Цикл из 3х эпох\n","1 эпоха приблизительно 30 минут"],"metadata":{"id":"blWzXoyHf0Yr"}},{"cell_type":"code","source":["epochs = 3\n","# Перебор обучения по эпохам\n","for e in range(epochs):\n","\n","    fake_label = np.zeros((batch_size, 1))  # Присваиваем метку 0 всем фейковым (сгенерированным) изображениям\n","    real_label = np.ones((batch_size, 1))  # Присваиваем метку 1 всем реальным изображениям\n","\n","    # Создание пустых списков для заполнения потерь генератора и дискриминатора\n","    g_losses = []\n","    d_losses = []\n","\n","    # Перебор обучения по пакетам\n","    for b in tqdm(range(len(train_hr_batches))):\n","        lr_imgs = train_lr_batches[b]  # Получение пакета LR изображений для обучения\n","        hr_imgs = train_hr_batches[b]  # Получение пакета HR изображений для обучения\n","\n","        fake_imgs = generator.predict_on_batch(lr_imgs)  # Сгенерированные изображения\n","\n","        # Сначала обучаем дискриминатор на фейковых и реальных HR изображениях\n","        discriminator.trainable = True\n","        d_loss_gen = discriminator.train_on_batch(fake_imgs, fake_label)\n","        d_loss_real = discriminator.train_on_batch(hr_imgs, real_label)\n","\n","        # Затем обучаем генератор, фиксируя дискриминатор как неподлежащий обучению\n","        discriminator.trainable = False\n","\n","        # Усредняем потери дискриминатора только для отчетности\n","        d_loss = 0.5 * np.add(d_loss_gen, d_loss_real)\n","\n","        # Извлекаем признаки VGG для вычисления потери\n","        image_features = vgg.predict(hr_imgs)\n","\n","        # Обучаем генератор с использованием GAN\n","        # Помните, у нас есть 2 потери: адверсарная потеря и потеря содержания (VGG)\n","        g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs], [real_label, image_features])\n","\n","        # Сохраняем потери в список, чтобы потом усреднить и сообщить\n","        d_losses.append(d_loss)\n","        g_losses.append(g_loss)\n","\n","    # Преобразуем списки потерь в массивы для усреднения\n","    g_losses = np.array(g_losses)\n","    d_losses = np.array(d_losses)\n","\n","    # Вычисляем средние потери для генератора и дискриминатора\n","    g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n","    d_loss = np.sum(d_losses, axis=0) / len(d_losses)\n","\n","    # Сообщаем о прогрессе обучения\n","    print(\"эпоха:\", e+1, \"g_loss:\", g_loss, \"d_loss:\", d_loss)\n","\n","    if (e+1) % 10 == 0:  # Измените частоту сохранения модели, при необходимости\n","        # Сохраняем генератор после каждых n эпох (обычно 10 эпох)\n","        generator.save(\"gen_e_\" + str(e+1) + \".h5\")"],"metadata":{"id":"_M0g2b7pQ5xX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Вывод результата"],"metadata":{"id":"Ci3gmvnugGfR"}},{"cell_type":"code","source":["from keras.models import load_model\n","from numpy.random import randint\n","\n","[X1, X2] = [X_valid, y_valid]\n","ix = randint(0, len(X1), 1)\n","src_image, tar_image = X1[ix], X2[ix]\n","gen_image = generator.predict(src_image)\n","\n","plt.figure(figsize=(16, 8))\n","plt.subplot(231)\n","plt.title('LR Image')\n","plt.imshow(src_image[0,:,:,:], cmap = 'gray')\n","plt.subplot(232)\n","plt.title('Superresolution')\n","plt.imshow(cv2.cvtColor(gen_image[0,:,:,:], cv2.COLOR_BGR2GRAY),cmap = 'gray')\n","plt.subplot(233)\n","plt.title('Orig. HR image')\n","plt.imshow(tar_image[0,:,:,:], cmap = 'gray')\n","\n","plt.show()"],"metadata":{"id":"_VOYA49JQ6VJ"},"execution_count":null,"outputs":[]}]}